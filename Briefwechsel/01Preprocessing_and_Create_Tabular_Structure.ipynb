{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-possible",
   "metadata": {},
   "source": [
    "# Preprocessing of the \"Briefwechsel\"\n",
    "\n",
    "This notebook \n",
    "1. Partially cleans plain text of Husserl's correspondence contained in *HuaDok III, 1-9 - Briefwechsel (1993)* \n",
    "2. Segmentates the letters to obtain a tabular structure\n",
    "3. Generates .txt files of the cleaned text\n",
    "4. And .csv files from the segmentated text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preceding-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### I will use regex and pandas libraries\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "proved-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ open the file\n",
    "with open(\"Vol1.txt\", encoding =\"utf8\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-genius",
   "metadata": {},
   "source": [
    "# 1: OCR postcorrection, cleaning wrong characters\n",
    "In this first part of the code I replace wrong characters with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cross-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace0 = re.sub(\" +\", \" \", text)\n",
    "replace1 = re.sub(r\"ã\", \"ä\", replace0)\n",
    "replace2 = re.sub(r\"õ\", \"ö\", replace1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sapphire-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Next re.sub will match words ending with capital B \n",
    "############ We need the following function to replace only the last charachter of the match object\n",
    "############ source: https://pynative.com/python-regex-replace-re-sub/#h-regex-replacement-function\n",
    "\n",
    "def convert_to_Eszett(match_obj):\n",
    "    if match_obj.group() is not None:\n",
    "        word = match_obj.group()\n",
    "        word = word[0:-1]\n",
    "        word += \"ß\"\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imported-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace3 = re.sub(r\"\\w+B\\b\", convert_to_Eszett, replace2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "national-mitchell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VERBINDUNG', 'ELISABETH', 'HERAUSGEGEBEN', 'groBe', 'muBte', 'groBen', 'groBen', 'fleiBig', 'anlaBlich', 'groBe', 'groBen', 'auBerordentlich', 'SchlieBlich', 'VerheiBungen', 'lieBe', 'MiBverdienst', 'bloBes', 'hieBe', 'groBen', 'groBe', 'groBer', 'anzuschlieBen', 'VerheiBung', 'muBten', 'groBe', 'groBer', 'groBen', 'schlieBt', 'auBerordentliche', 'verstieBen', 'maBgebend', 'miBtrauisch', 'groBen', 'ieBen', 'dahinflieBe', 'EinfluBreichen', 'EinfluBreichen', 'groBe', 'fuBt', 'auffaBt', 'SchluBkapitel', 'MeBversuchen', 'groBen', 'groBe', 'MeBkunst', 'muBte', 'entschlieBen', 'MeBkunst', 'auBerwesentlich', 'ausschlieBen', 'MaBe', 'groBen', 'MaBe', 'schlieBe', 'GroBes', 'FBrentano', 'einigennaBen', 'unvergeBlichen', 'groBe', 'muBte', 'groBe', 'verdrieBen', 'auszuschlieBen', 'muBte', 'HeiBt', 'groBen', 'venniBt', 'heiBen', 'muBte', 'FBrentano', 'FBrentano', 'groBer', 'groBe', 'MaBe', 'groBe', 'groBen', 'groBen', 'auBer', 'ausschlieBt', 'bloBen', 'groBe', 'groBe', 'GruBe', 'heiBt', 'auBer', 'GriiBen', 'groBem', 'heiBt', 'heiBt', 'groBe', 'bloBe', 'heiBt', 'gehaBt', 'befaBt', 'einschlieBlichen', 'einschlieBlich', 'bloBe', 'aufgefaBt', 'einschlieBen', 'schlieBen', 'bloBe', 'paBt', 'AufgefaBten', 'auffaBt', 'muBte', 'meinheitsbewuBtseins', 'heiBt', 'schlieBe', 'GruBe', 'gewiBe', 'groBem', 'heiBt', 'miBzuverstehen', 'bloBe', 'weiBes', 'bloBe', 'bloBen', 'weiBe', 'bewuBten', 'ErkenntniBtheorie', 'schlieBe', 'groBe', 'etatsmaBigen', 'weiBen', 'veranlaBt', 'genieBen', 'groBe', 'groBe', 'schlieBe', 'groBen', 'muBte', 'GruBe', 'auBerordentliche', 'heiBt', 'SchluBfolgerung', 'heiBt', 'schlieBlich', 'MaBe', 'laBt', 'groBe', 'hinreiBen', 'schlieBlich', 'groBen', 'muBte', 'einigermaBen', 'auBer', 'groBe', 'groBen', 'auBerordentlichen', 'auBerordentlichen', 'AusmaBe', 'muBte', 'groBe', 'muBte', 'groBen', 'ausschlieBlich', 'schlieBt', 'heiBt', 'VollbewuBt', 'genieBe', 'schlieBende', 'heiBe', 'heiBen', 'groBen', 'groBe', 'schlieBe', 'GroBe', 'GruBe', 'bewuBt', 'beeinfluBen', 'GruBe', 'bloBes', 'bloBes', 'bloBe', 'bloBe', 'bloBen', 'SchlieBen', 'bloBe', 'SchluBfolgerungen', 'SchluBfolgerung', 'ausschlieBlich', 'muBten', 'SchluBverfahrens', 'groBe', 'schlieBl', 'schlieBen', 'groBem', 'bloBe', 'genieBen', 'abgefaBt', 'wuBte', 'StraBburg', 'zusammengefaBt', 'GewiBheit', 'GewiBheit', 'UngewiBheit', 'GewiBheit', 'maBgebende', 'GewiBheit', 'laBt', 'bewuBtseins', 'bloBer', 'AllgemeinheitsbewuBtsein', 'meinheitsbewuBtsein', 'AllgemeinheitsbewuBtseins', 'aufgefaBt', 'EinheitsbewuBtseins', 'aufgefaBten', 'faBt', 'gefaBt', 'bloBe', 'laBt', 'beimiBt', 'einschlieBt', 'bewuBt', 'VemunftbewuBtsein', 'dahinflieBenden', 'groBem', 'groBe']\n"
     ]
    }
   ],
   "source": [
    "########## The following regular expression matches words containing capital B\n",
    "########## but not words that start with B\n",
    "\n",
    "x = re.findall(r\"\\b(?!B)[a-zA-Z]*B[a-zA-Z]*\", replace3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inner-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ As in the last re.sub match, \n",
    "############ we need the following function to replace only the last charachter of the match object\n",
    "############ source: https://pynative.com/python-regex-replace-re-sub/#h-regex-replacement-function\n",
    "\n",
    "def convert_to_Eszett2(match_obj):\n",
    "    if match_obj.group() is not None:\n",
    "        word = match_obj.group()\n",
    "        if all(letter.isupper() for letter in word):\n",
    "            return word\n",
    "        else:\n",
    "            for letter in word:\n",
    "                if letter == \"B\":\n",
    "                    word = word.replace(\"B\",\"ß\")\n",
    "                    return word\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cubic-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = re.sub(r\"\\b(?!B)[a-zA-Z]*B[a-zA-Z]*\", convert_to_Eszett2, replace3)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-corporation",
   "metadata": {},
   "source": [
    "## Note\n",
    "Although further cleaning can be done (footnotes, page/line numbers, line breaks). We can already perform some techniques of computational text analysis with this corpus. \n",
    "\n",
    "For later usability, I will create a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "professional-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_postcorrection(txt_file):\n",
    "    \n",
    "    with open(txt_file, newline='', encoding=\"utf8\", errors='ignore') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    replace0 = re.sub(' +', ' ', text)\n",
    "    replace1 = re.sub(r\"ã\", \"ä\", replace0)\n",
    "    replace2 = re.sub(r\"õ\", \"ö\", replace1)\n",
    "    \n",
    "    ############ Next re.sub will match words ending with capital B \n",
    "    ############ We need the following function to replace only the last charachter of the match object\n",
    "    ############ source: https://pynative.com/python-regex-replace-re-sub/#h-regex-replacement-function\n",
    "    def convert_to_Eszett(match_obj):\n",
    "        if match_obj.group() is not None:\n",
    "            word = match_obj.group()\n",
    "            word = word[0:-1]\n",
    "            word += \"ß\"\n",
    "            return word\n",
    "        \n",
    "    replace3 = re.sub(r\"\\w+B\\b\", convert_to_Eszett, replace2)\n",
    "    \n",
    "    ############ As in the last re.sub match, \n",
    "    ############ we need the following function to replace only the B of the match object\n",
    "    ############ source: https://pynative.com/python-regex-replace-re-sub/#h-regex-replacement-function\n",
    "    def convert_to_Eszett2(match_obj):\n",
    "        if match_obj.group() is not None:\n",
    "            word = match_obj.group()\n",
    "            if all(letter.isupper() for letter in word): # we want to ignore words in uppercase\n",
    "                return word\n",
    "            else:\n",
    "                for letter in word:\n",
    "                    if letter == \"B\":\n",
    "                        word = word.replace(\"B\",\"ß\")\n",
    "                        return word\n",
    "                 \n",
    "                # This expression matches words containing B but not starting with B   \n",
    "    final_text = re.sub(r\"\\b(?!B)[a-zA-Z]*B[a-zA-Z]*\", convert_to_Eszett2, replace3)\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-flashing",
   "metadata": {},
   "source": [
    "# 2. Creating a new structure: Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "african-reality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Husserl an Brentano, 29. XII. 1886', 'Husserl an Brentano, 23. X. 1891', 'Husserl an Brentano, 29. XII. 1892', 'Husserl an Brentano, ca. Anfang 1894', 'Husserl an Brentano, ca. 15. 1. 1898', 'Husserl an Brentano, 11./15. X. 1904', 'Husserl an Brentano, 27. III. 1905', 'Husserl an Brentano, 22. VIII. 1906', 'Husserl an Brentano, 5. IV. 1907', 'Husserl an Brentano, 6. V. 1907', 'Husserl an Brentano, 22. XI. 1911', 'Husserl an Brentano, 31. XII. 1913', 'Husserl an Höfler, 13. VII. 1897', 'Husserl an Höfler, 1. V. 1901', 'Husserl an Marty, 7. VII. 1901', 'Husserl an Marty, 11J13. X. 1905', 'Husserl an Masaryk, ca. 25. XII. 1902', 'Husserl an Masaryk, 3. X. 1921', 'Husserl an Masaryk, 2. III. 1922', 'Husserl an Masaryk, 3. 1. 1935', 'Husserl an Meinong, 22. V. 1891', 'Husserl an Meinong, ca. Juli 1891', 'Husserl an Meinong, 25. 1. 1892', 'Husserl an Meinong, 16. II. 1892', 'Husserl an Meinong, 14. II. 1894', 'Husserl an Meinong, 22. XI. 1894', 'Husserl an Meinong, 19. VII. 1896', 'Husserl an Meinong, 27. VIII. 1900', 'Husserl an Meinong, 29. XI. 1901', 'Husserl an Meinong, 11. XII. 1904', 'Husserl an D. Meinong, 17. VI. 1921', 'Husserl an Stumpf, ca. Februar 1890', 'Husserl an Stumpf, 21. VI. 1899', 'Husserl an Stumpf, 11. V. 1902', 'Husserl an Stumpf, ca. 1908', 'Husserl an Stumpf, 1919', 'Husserl an Twardowski, 13. VII. 1928', 'Husserl an Utitz, 2. XI. 1931']\n",
      "---------------------------------------------\n",
      "['Brentano an Husserl, 27. IV. 1891', 'Brentano an Husserl, ca. Mai 1891', 'Brentano an Husserl, 26. 1. 1892', 'Brentano an Husserl, 3.1. 1893', 'Brentano an Husserl, 26. XII. 1893', 'Brentano an Husserl, ca. Ende Dezember 1894', 'Brentano an Husserl, 7. 1. 1896', 'Brentano an Husserl, 5. II. 1898', 'Brentano an Husserl, 28. VII. 1900', 'Brentano an Husserl, 7. X. 1904', 'Brief an Husserl, ca. Mai 1891', 'Brentano an Husserl, 21. X. 1904', 'Brentano an Husserl, 9. 1. 1905', 'Brentano an Husserl, 1. VIII. 1906', 'Brentano an Husserl, 27. VIII. 1906', 'Brentano an Husserl, 9. V. 1907', 'Brentano an Husserl, 16. 1. 1908', 'Brentano an Husserl, 17. XI.1911', 'Brentano an Husserl, 6. IV. 1916', 'Brentano an Husserl, 30. IV. 1916', 'Höfler an Husserl, 16. II. 1893', 'Höfler an Husserl, 11. VII. 1897', 'Marty an Husserl, 29. 1. 1887', 'Marty an Husserl, 7 JS. VI. 1901', 'Marty an Husserl, 17. VIII. 1901', 'Marty an Husserl, 25. VI. 1902', 'Marty an Husserl, 11. VII. 1903', 'Marty an Husserl, 7. III. 1904', 'Marty an Husserl, 9. X. 1905', 'Marty an Husserl, 9. 1. 1908', 'Marty an Husserl, 5. IV. 1910', 'Marty an Husserl, 15. III. 1911', 'Masaryk an Husserl, 11. IX. 1877', 'Masaryk an Husserl, 20. 1. 1878', 'Masaryk an Husserl, 1. VII. 1878', 'Masaryk an Husserl, 7. 1. 1879', 'Masaryk an Husserl, 1. 1. 1902', 'Masaryk an Husserl, 12. 11.1922', 'Masaryk an Husserl, 14. III. 1929', 'Skrach an Husserl, 31. 1.1930', 'Masaryk an Husserl, 10. III. 1930', 'Meinong an Husserl, 17. V. 1891', 'Meinong an Husserl, 19. VI. 1891', 'Meinong an Husserl, 25. XI. 1901', 'Meinong an Husserl, 10. IV. 1902', 'Meinong an Husserl, 6. XII. 1904', 'Kowarzik an Husserl, 25. II. 1931', 'Twardowski an Husserl, 17. VIII. 1928', 'Utitz an Husserl, 22. XI.1930', 'Utitz an Husserl, 6. XI. 1932']\n"
     ]
    }
   ],
   "source": [
    "############ The following expressions indicate the beginning of a letter\n",
    "\n",
    "letter_by_Husserl = re.findall(r\"Husserl an.*?\\d*\\.*\\d{4}\", final_text)\n",
    "letter_to_Husserl =re.findall(r\"\\w+ an Husserl.*?\\d*\\.*\\d{4}\", final_text)\n",
    "print(letter_by_Husserl)\n",
    "print(\"---------------------------------------------\")\n",
    "print(letter_to_Husserl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "theoretical-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 88\n"
     ]
    }
   ],
   "source": [
    "all_letters = re.findall(r\"Husserl an.*?\\d*\\.*\\d{4}|\\w+ an Husserl.*?\\d*\\.*\\d{4}\", final_text)\n",
    "split = re.split(r\"Husserl an.*?\\d*\\.*\\d{4}|\\w+ an Husserl.*?\\d*\\.*\\d{4}\", final_text)\n",
    "\n",
    "print(len(split), len(all_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "verified-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_df = []\n",
    "index = 0\n",
    "\n",
    "for title in all_letters:\n",
    "    \n",
    "    ########## extracting the year\n",
    "    #year = re.findall(r\"\\d{4}\", title)\n",
    "    mat_obj = re.search(r\"\\d{4}\", title)\n",
    "    if mat_obj.group() is not None:\n",
    "        year = mat_obj.group()\n",
    "    \n",
    "    ######### sender and recipient\n",
    "    if title in letter_by_Husserl:\n",
    "        sender = \"Husserl\"\n",
    "        rec = title.split()\n",
    "        recipient = rec[2]\n",
    "    else:\n",
    "        recipient = \"Husserl\"\n",
    "        send = title.split()\n",
    "        sender = send[0]\n",
    "    \n",
    "    ########## indicating position of the letter in the split list\n",
    "    index = index + 1    \n",
    "    \n",
    "    letter = [title, year, sender, recipient, split[index]]\n",
    "    \n",
    "    list_for_df.append(letter)\n",
    "    \n",
    "#print(list_for_df[75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "partial-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    title  year      sender    recipient  \\\n",
      "0      Husserl an Brentano, 29. XII. 1886  1886     Husserl    Brentano,   \n",
      "1       Brentano an Husserl, 27. IV. 1891  1891    Brentano      Husserl   \n",
      "2       Brentano an Husserl, ca. Mai 1891  1891    Brentano      Husserl   \n",
      "3        Husserl an Brentano, 23. X. 1891  1891     Husserl    Brentano,   \n",
      "4        Brentano an Husserl, 26. 1. 1892  1892    Brentano      Husserl   \n",
      "..                                    ...   ...         ...          ...   \n",
      "83   Husserl an Twardowski, 13. VII. 1928  1928     Husserl  Twardowski,   \n",
      "84  Twardowski an Husserl, 17. VIII. 1928  1928  Twardowski      Husserl   \n",
      "85          Utitz an Husserl, 22. XI.1930  1930       Utitz      Husserl   \n",
      "86          Husserl an Utitz, 2. XI. 1931  1931     Husserl       Utitz,   \n",
      "87          Utitz an Husserl, 6. XI. 1932  1932       Utitz      Husserl   \n",
      "\n",
      "                                               letter  \n",
      "0   \\n\\n\\n\\n\\n\\nHochverehrter Herr Professor!\\n\\nH...  \n",
      "1   \\n\\n\\n\\nGeehrtester Herr Doctor!\\n\\nFreundlich...  \n",
      "2   \\n\\n\\n\\n\\n\\n\\n\\nLieber Herr Doctor!\\n\\nSchönbü...  \n",
      "3   \\n\\n\\n\\n\\n\\nHochverehrter Herr Professor!\\n\\nH...  \n",
      "4   \\n\\n\\n\\n\\n\\nLieber Herr Doctor!\\n\\nWien, d-cen...  \n",
      "..                                                ...  \n",
      "83  \\n\\n181\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSehr verehrter Herr...  \n",
      "84  \\n\\n\\n\\nLemberg/: Lwów:/, 17. August, 1928. Ho...  \n",
      "85  \\n\\n\\n\\n\\n\\n\\n\\nHochverehrter Herr Geheimrat!\\...  \n",
      "86  \\n\\n\\n\\n20 Freiburg i. Br., den 2. XI. 1931\\n\\...  \n",
      "87   (Abschrift)\\n\\n\\n\\nHalle, 6. 11. 32.\\n\\n20 An...  \n",
      "\n",
      "[88 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame (list_for_df, columns = [\"title\", \"year\", \"sender\", \"recipient\", \"letter\"])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-uncle",
   "metadata": {},
   "source": [
    "## Note 2\n",
    "Again, I put all together in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "parliamentary-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_structure(text):\n",
    "    \n",
    "    #with open(file, 'w', encoding='utf-8') as f:\n",
    "     #   text = f.read()\n",
    "    \n",
    "    all_letters = re.findall(r\"Husserl an.*?\\d*\\.*\\d{4}|\\w+ an Husserl.*?\\d*\\.*\\d{4}\", text)\n",
    "    letter_by_Husserl = re.findall(r\"Husserl an.*?\\d*\\.*\\d{4}\", text)\n",
    "    \n",
    "    split = re.split(r\"Husserl an.*?\\d*\\.*\\d{4}|\\w+ an Husserl.*?\\d*\\.*\\d{4}\", text)\n",
    "    \n",
    "    list_for_df = []\n",
    "    index = 0\n",
    "\n",
    "    for title in all_letters:\n",
    "    \n",
    "        ########## extracting the year\n",
    "        mat_obj = re.search(r\"\\d{4}\", title)\n",
    "        if mat_obj.group() is not None:\n",
    "            year = mat_obj.group()\n",
    "    \n",
    "        ######### sender and recipient\n",
    "        if title in letter_by_Husserl:\n",
    "            sender = \"Husserl\"\n",
    "            rec = title.split()\n",
    "            recipient = rec[2]\n",
    "        else:\n",
    "            recipient = \"Husserl\"\n",
    "            send = title.split()\n",
    "            sender = send[0]\n",
    "    \n",
    "        ########## indicating position of the letter in the split list\n",
    "        index = index + 1    \n",
    "    \n",
    "        letter = [title, year, sender, recipient, split[index]]\n",
    "    \n",
    "        list_for_df.append(letter)\n",
    "        \n",
    "        df = pd.DataFrame (list_for_df, columns = [\"title\", \"year\", \"sender\", \"recipient\", \"letter\"])\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-yahoo",
   "metadata": {},
   "source": [
    "# 3. Loop in all volumes, new txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "facial-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## For-in-loop using the ocr_postcorrection function\n",
    "\n",
    "vol = 0\n",
    "for vulume in range(9):\n",
    "    vol += 1\n",
    "    file = \"Vol%s.txt\" % (str(vol))\n",
    "    new_file_name = \"HuaDokIII-%s.txt\" % (str(vol))\n",
    "    with open(new_file_name, 'w', encoding='utf-8') as f:\n",
    "        f.write(ocr_postcorrection(file))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-industry",
   "metadata": {},
   "source": [
    "# 4. Loop-in all volumes, new csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fossil-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## For-in-loop using the ocr_postcorrection function\n",
    "########## When deleting the comments, the txt and the csv files are generated simultaneously\n",
    "\n",
    "vol = 0\n",
    "for vulume in range(9):\n",
    "    \n",
    "    vol += 1\n",
    "    file = \"Vol%s.txt\" % (str(vol))\n",
    "    #new_txt_name = \"HuaDokIII-%s.txt\" % (str(vol))\n",
    "    name_csv = \"TABULAR_HuaDokIII-%s.csv\" % (str(vol))\n",
    "\n",
    "    postcorrection = ocr_postcorrection(file)\n",
    "    \n",
    "    #with open(new_txt_name, 'w', encoding='utf-8') as f:\n",
    "     #   f.write(postcorrection)\n",
    "    \n",
    "    tabular_structure(postcorrection).to_csv(name_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
